{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55c8afde-9b18-4b6a-9ee5-33924bdb4f16",
   "metadata": {},
   "source": [
    "# REST Inference for model server deployment "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c004acc-13cd-4917-8480-592c7c2d623b",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Change the following variable settings to match your deployed model's *Inference endpoint*. You must edit the endpoint by specifying port 8888, as shown in the following example:\n",
    "\n",
    "```\n",
    "deployed_model_name = \"fraud\"\n",
    "infer_endpoint = \"http://fraud-predictor-userx-workshop.apps.clusterx.sandboxx.opentlc.com:8888\"\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0de65d02-84a6-4cff-882e-551cdd42b486",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployed_model_name = \"fraud\"\n",
    "infer_endpoint = \"http://fraud-predictor-<project-name>.<cluster>.com:8888\"\n",
    "infer_url = f\"{infer_endpoint}/v2/models/{deployed_model_name}/infer\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94f9ece-e9cf-44e2-a8a2-73160186aee8",
   "metadata": {},
   "source": [
    "## Request Function\n",
    "\n",
    "Build and submit the REST request. \n",
    "\n",
    "Note: You submit the data in the same format that you used for an ONNX inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "54b9386f-683a-4880-b780-c40bec3ab9f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "def rest_request(data):\n",
    "    json_data = {\n",
    "        \"inputs\": [\n",
    "            {\n",
    "                \"name\": \"dense_input\",\n",
    "                \"shape\": [1, 5],\n",
    "                \"datatype\": \"FP32\",\n",
    "                \"data\": data\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    headers = {\"Authorization\": \"Bearer sha256~acorWZic4cHcb31KnQh4iN7LJEhYa8kmaYWLFUKl9xs\"}\n",
    "    response = requests.post(infer_url, json=json_data, headers=headers, verify=False)\n",
    "    response_dict = response.json()\n",
    "    return response_dict['outputs'][0]['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5f871f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the scaler\n",
    "import pickle\n",
    "with open('artifact/scaler.pkl', 'rb') as handle:\n",
    "    scaler = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93c9d75-4a26-4492-894e-1467211f9883",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [0.3111400080477545, 1.9459399775518593, 1.0, 0.0, 0.0]\n",
    "prediction = rest_request(scaler.transform([data]).tolist()[0])\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829c88d6-05e0-4be3-b96b-e0e6df0ad740",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshhold = 0.95\n",
    "\n",
    "if (prediction[0] > threshhold):\n",
    "    print('fraud')\n",
    "else:\n",
    "    print('not fraud')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7b17c0",
   "metadata": {},
   "source": [
    "## Example 1: user buys a coffee\n",
    "\n",
    "In this example, the user is buying a coffee. The parameters given to the model are:\n",
    "* same location as the last transaction (distance=0)\n",
    "* same median price as the last transaction (ratio_to_median=1)\n",
    "* using a pin number (pin=1)\n",
    "* using the credit card chip (chip=1)\n",
    "* not an online transaction (online=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb2bb8f-48f5-42d5-ab3e-d30844efe690",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [0.0, 1.0, 1.0, 1.0, 0.0]\n",
    "prediction = rest_request(scaler.transform([data]).tolist()[0])\n",
    "prediction\n",
    "threshhold = 0.95\n",
    "\n",
    "if (prediction[0] > threshhold):\n",
    "    print('The model predicts that this is fraud')\n",
    "else:\n",
    "    print('The model predicts that this is not fraud')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db10b280",
   "metadata": {},
   "source": [
    "## Example 2: fraudulent transaction\n",
    "\n",
    "In this example, someone stole the user's credit card and is buying something online. The parameters given to the model are:\n",
    "* very far away from the last transaction (distance=100)\n",
    "* median price similar to the last transaction (ratio_to_median=1.2)\n",
    "* not using a pin number (pin=0)\n",
    "* not using the credit card chip (chip=0)\n",
    "* is an online transaction (online=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a8d5ed-26a2-427f-a2db-18d1feacdb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [100, 1.2, 0.0, 0.0, 1.0]\n",
    "prediction = rest_request(scaler.transform([data]).tolist()[0])\n",
    "prediction\n",
    "threshhold = 0.95\n",
    "\n",
    "if (prediction[0] > threshhold):\n",
    "    print('The model predicts that this is fraud')\n",
    "else:\n",
    "    print('The model predicts that this is not fraud')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
