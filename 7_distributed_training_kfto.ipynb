{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Fraud Detection model with the Kubeflow Training Operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example fraud detection model is small and quickly trained. For many large models, training requires multiple GPUs and often multiple machines. In this notebook, you learn how to train a model by using the Kubeflow Training Operator on OpenShift AI to scale out model training. You use the Training Operator SDK to create a PyTorchJob that executes the provided model training script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install the Training Operator SDK\n",
    "\n",
    "The Training Operator SDK is not available by default with the Tensorflow workbench image. Run the following command to install it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install \"kubeflow @ git+https://github.com/opendatahub-io/kubeflow-sdk.git@v0.2.1+rhai0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kubeflow.trainer import TrainerClient\n",
    "from kubeflow.trainer.rhai import TransformersTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(\"./kfto-scripts\")  # needed to make training function available in the notebook\n",
    "from train_pytorch_cpu import train_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kubernetes import client\n",
    "from kubeflow.common.types import KubernetesBackendConfig\n",
    "\n",
    "api_server = \"https://XXXX\"\n",
    "token = \"sha256~XXXX\"\n",
    "\n",
    "configuration = client.Configuration()\n",
    "configuration.host = api_server\n",
    "configuration.api_key = {\"authorization\": f\"Bearer {token}\"}\n",
    "# Un-comment if your cluster API server uses a self-signed certificate or an un-trusted CA\n",
    "# configuration.verify_ssl = False\n",
    "\n",
    "backend_config = KubernetesBackendConfig(\n",
    "      client_configuration=configuration,\n",
    "      namespace=\"fraud-detection\"  # your namespace\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a PyTorchJob\n",
    "\n",
    "Use the Training Operator SDK client to submit a PyTorchJob.\n",
    "\n",
    "The model training script is imported from the `kfto-scripts` folder.\n",
    "\n",
    "The model training script loads and distributes the training data set among nodes, performs distributed training, evaluates by using the test data set, and exports the trained model to ONNX format and uploads it to the S3 bucket that is specified in the provided connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = TransformersTrainer(\n",
    "    func=train_func,\n",
    "    num_nodes=2,\n",
    "    resources_per_node={\"nvidia.com/gpu\": 0},\n",
    "    packages_to_install=[\n",
    "        \"s3fs\",\n",
    "        \"boto3\",\n",
    "        \"scikit-learn\",\n",
    "        \"onnx\",\n",
    "    ],\n",
    "    env={\n",
    "          \"AWS_ACCESS_KEY_ID\": os.environ.get(\"AWS_ACCESS_KEY_ID\"),\n",
    "          \"AWS_S3_BUCKET\": os.environ.get(\"AWS_S3_BUCKET\"),\n",
    "          \"AWS_S3_ENDPOINT\": os.environ.get(\"AWS_S3_ENDPOINT\"),\n",
    "          \"AWS_SECRET_ACCESS_KEY\": os.environ.get(\"AWS_SECRET_ACCESS_KEY\"),\n",
    "      }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_client = TrainerClient(backend_config=backend_config)\n",
    "runtime = trainer_client.get_runtime(\"torch-distributed\")\n",
    "job_name = trainer_client.train(\n",
    "    trainer=trainer,\n",
    "    runtime=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_client.wait_for_job_status(\n",
    "      name=job_name,\n",
    "      status={\"Running\"},\n",
    "      timeout=3600,  # 1 hour\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Streaming logs ---\")\n",
    "for log_line in trainer_client.get_job_logs(name=job_name, follow=True):\n",
    "  print(log_line, end='\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
