{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the target device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = (\n",
    "    \"cuda\" if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Data\n",
    "\n",
    "The CSV data that you use to train the model contains the following fields:\n",
    "\n",
    "* **distancefromhome** - The distance from home where the transaction happened.\n",
    "* **distancefromlast_transaction** - The distance from the last transaction that happened.\n",
    "* **ratiotomedianpurchaseprice** - The ratio of purchased price compared to median purchase price.\n",
    "* **repeat_retailer** - If it's from a retailer that already has been purchased from before.\n",
    "* **used_chip** - If the credit card chip was used.\n",
    "* **usedpinnumber** - If the PIN number was used.\n",
    "* **online_order** - If it was an online order.\n",
    "* **fraud** - If the transaction is fraudulent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "feature_indexes = [\n",
    "    1,  # distance_from_last_transaction\n",
    "    2,  # ratio_to_median_purchase_price\n",
    "    4,  # used_chip\n",
    "    5,  # used_pin_number\n",
    "    6,  # online_order\n",
    "]\n",
    "\n",
    "label_indexes = [\n",
    "    7  # fraud\n",
    "]\n",
    "\n",
    "train_df = pd.read_csv('data/train.csv')\n",
    "labels_df = train_df.iloc[:, label_indexes]\n",
    "train_df = train_df.iloc[:, feature_indexes]\n",
    "train_df_tensor = torch.tensor(train_df.values, dtype=torch.float).to(device)\n",
    "labels_df_tensor = torch.tensor(labels_df.values, dtype=torch.float).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# like scikit learn standard scaler\n",
    "class TorchStandardScaler:\n",
    "    def __init__(self):\n",
    "        self.mean = None\n",
    "        self.std = None\n",
    "\n",
    "    def fit(self, tensor):\n",
    "        self.mean = tensor.mean(dim=0, keepdim=False)\n",
    "        self.std = tensor.std(dim=0, keepdim=False)\n",
    "\n",
    "    def transform(self, tensor):\n",
    "        return (tensor - self.mean) / self.std\n",
    "\n",
    "    def fit_transform(self, tensor):\n",
    "        self.fit(tensor)\n",
    "        return self.transform(tensor)\n",
    "\n",
    "\n",
    "train_df_tensor = torch.tensor(train_df.values, dtype=torch.float).to(device)\n",
    "scaler = TorchStandardScaler()\n",
    "scaler.fit(train_df_tensor)\n",
    "scaler.mean, scaler.std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create PyTorch Datasets and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class CSVDataset(Dataset):\n",
    "    def __init__(self, csv_file, pyarrow_fs=None, transform=None, target_transform=None):\n",
    "        self.feature_indexes = feature_indexes\n",
    "        self.label_indexes = label_indexes\n",
    "        \n",
    "        if pyarrow_fs:\n",
    "            with pyarrow_fs.open_input_file(csv_file) as file:\n",
    "                training_table = pv.read_csv(file)\n",
    "            self.data = training_table.to_pandas()\n",
    "        else:\n",
    "            self.data = pd.read_csv(csv_file)\n",
    "\n",
    "\n",
    "        self.features = self.data.iloc[:, self.feature_indexes].values\n",
    "        self.labels = self.data.iloc[:, self.label_indexes].values\n",
    "        self.features = torch.tensor(self.features, dtype=torch.float).to(device)\n",
    "        self.labels = torch.tensor(self.labels, dtype=torch.float).to(device)\n",
    "\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "        if self.transform:\n",
    "            self.features = self.transform(self.features)\n",
    "        if self.target_transform:\n",
    "            self.labels = self.target_transform(self.labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        features = self.features[idx]\n",
    "        label = self.labels[idx]\n",
    "        return features, label\n",
    "\n",
    "\n",
    "training_data = CSVDataset('data/train.csv')\n",
    "validation_data = CSVDataset('data/validate.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "training_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "validation_dataloader = DataLoader(validation_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model\n",
    "\n",
    "The model is a simple, fully-connected, deep neural network, containing three hidden layers and one output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, scaler):\n",
    "        super().__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(5, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        self.scaler = scaler\n",
    "\n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():\n",
    "            x_pre = self.scaler.transform(x)\n",
    "        probs = self.linear_relu_stack(x_pre)\n",
    "        return probs\n",
    "\n",
    "\n",
    "model = NeuralNetwork(scaler).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % round(size / batch_size / 10) == 0:\n",
    "            loss = loss.item()\n",
    "            current = batch * batch_size + len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def eval_loop(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    eval_loss, correct = 0, 0\n",
    "\n",
    "    all_preds = torch.tensor([])\n",
    "    all_labels = torch.tensor([])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            eval_loss += loss_fn(pred, y).item()\n",
    "            correct += torch.eq(torch.round(pred), y).sum().item()\n",
    "\n",
    "            pred_labels = torch.round(pred)\n",
    "            all_preds = torch.cat((all_preds, pred_labels.cpu()))\n",
    "            all_labels = torch.cat((all_labels, y.cpu()))\n",
    "\n",
    "    precision = precision_score(all_labels, all_preds)\n",
    "    recall = recall_score(all_labels, all_preds)\n",
    "\n",
    "    eval_loss /= num_batches\n",
    "    accuracy = correct / size * 100\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"loss\": eval_loss,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a model is often the most time-consuming part of the machine learning process.  Large models can take multiple GPUs for days.  Expect the training on CPU for this very simple model to take a minute or more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "loss_fn = nn.BCELoss().to(device)\n",
    "\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
    "\n",
    "num_epochs = 2\n",
    "for t in range(num_epochs):\n",
    "    print(f\"\\nEpoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(training_dataloader, model, loss_fn, optimizer)\n",
    "    metrics = eval_loop(validation_dataloader, model, loss_fn)\n",
    "    print(f\"Eval Metrics: \\n Accuracy: {(metrics['accuracy']):>0.1f}%, Avg loss: {metrics['loss']:>8f}, \"\n",
    "          f\"Precision: {metrics['precision']:.4f}, Recall: {metrics['recall']:.4f} \\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Eval Metrics: \\n Accuracy: {(metrics['accuracy']):>0.1f}%, Avg loss: {metrics['loss']:>8f}, \"\n",
    "      f\"Precision: {metrics['precision']:.4f}, Recall: {metrics['recall']:.4f} \\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_inference(test_data):\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        prediction = torch.round(model(test_data))\n",
    "\n",
    "    if prediction.item() == 1:\n",
    "        return \"fraud\"\n",
    "    else:\n",
    "        return \"NOT fraud\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# valid transaction\n",
    "valid_tx = torch.tensor([[0.0, 1.0, 1.0, 1.0, 0.0]]).to(device)\n",
    "prediction = run_inference(valid_tx)\n",
    "print(f\"The model thinks the valid transaction is {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fraudulent use case\n",
    "fraud_tx = torch.tensor([[100, 1.2, 0.0, 0.0, 1.0]]).to(device)\n",
    "prediction = run_inference(fraud_tx)\n",
    "print(f\"The model thinks the valid transaction is {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_df = pd.read_csv('data/test_sample.csv', )\n",
    "test_df = pd.read_csv('data/test.csv', )\n",
    "test_labels_df = test_df.iloc[:, label_indexes]\n",
    "test_data_df = test_df.iloc[:, feature_indexes]\n",
    "test_data_df_tensor = torch.tensor(test_data_df.values, dtype=torch.float).to(device)\n",
    "test_labels_df_tensor = torch.tensor(test_labels_df.values, dtype=torch.float).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    y_pred = model(test_data_df_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "correct = torch.eq(torch.round(y_pred), test_labels_df_tensor).sum().item()\n",
    "acc = (correct / len(y_pred)) * 100\n",
    "\n",
    "y_pred_cpu = torch.Tensor.cpu(torch.Tensor.cpu(torch.round(y_pred)))\n",
    "test_labels_df_tensor_cpu = torch.Tensor.cpu(torch.Tensor.cpu(test_labels_df_tensor))\n",
    "\n",
    "precision = precision_score(test_labels_df_tensor_cpu, y_pred_cpu)\n",
    "recall = recall_score(test_labels_df_tensor_cpu, y_pred_cpu)\n",
    "\n",
    "print(f\"Eval Metrics: \\n Accuracy: {acc:>0.1f}%, \"\n",
    "      f\"Precision: {precision:.4f}, Recall: {recall:.4f} \\n\")\n",
    "\n",
    "c_matrix = confusion_matrix(test_labels_df_tensor_cpu,\n",
    "                            y_pred_cpu)\n",
    "ConfusionMatrixDisplay(c_matrix).plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to ONNX\n",
    "\n",
    "If we want to use the model again without having the original neural network, we can save it as ONNX.  In addition, this format is useful for model serving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install onnx onnxscript onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(\"models/fraud/1\", exist_ok=True)\n",
    "dummy_input = torch.randn(1, 5, device=device)\n",
    "onnx_model = torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    \"models/fraud/1/model.onnx\",\n",
    "    input_names=[\"inputs\"],\n",
    "    output_names=[\"outputs\"],\n",
    "    dynamic_axes={\n",
    "        \"inputs\": {0: \"batch_size\"},\n",
    "    },\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Test the ONNX model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import onnx\n",
    "import onnxruntime as rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_test_data = test_data_df.values\n",
    "onnx_test_data = np.float32(onnx_test_data)\n",
    "\n",
    "onnx_test_labels = test_data_df.values\n",
    "onnx_test_labels = np.float32(onnx_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = rt.InferenceSession(\"models/fraud/1/model.onnx\", providers=rt.get_available_providers())\n",
    "input_name = sess.get_inputs()[0].name\n",
    "output_name = sess.get_outputs()[0].name\n",
    "input_name, output_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "onnx_output = sess.run([output_name], {input_name: onnx_test_data})[0]\n",
    "onnx_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = np.equal(np.round(onnx_output), test_labels_df).sum().item()\n",
    "acc = (correct / len(onnx_output)) * 100\n",
    "precision = precision_score(test_labels_df_tensor_cpu, np.round(onnx_output))\n",
    "recall = recall_score(test_labels_df, np.round(onnx_output))\n",
    "\n",
    "print(f\"Eval Metrics: \\n Accuracy: {acc:>0.1f}%, \"\n",
    "      f\"Precision: {precision:.4f}, Recall: {recall:.4f} \\n\")\n",
    "\n",
    "c_matrix = confusion_matrix(test_labels_df.values, np.round(onnx_output))\n",
    "ConfusionMatrixDisplay(c_matrix).plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check our ONNX output matches our original PyTorch Model Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_equal(np.round(y_pred.numpy()), np.round(onnx_output))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
