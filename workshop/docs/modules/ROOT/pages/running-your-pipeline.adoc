:_module-type: PROCEDURE

[id='running-your-pipeline']
= Running your pipeline

[role="_abstract"]
You can upload and run your pipeline directly from the pipeline editor. Use either your newly created pipeline or the provided `4 Train Save.pipeline` file.

.Prerequisites

* You set the S3 storage bucket keys, as described in xref:configuring-the-connection-to-storage.adoc[Configuring the connection to storage].

* You configured a pipeline server, as descibed in xref:enabling-ai-pipelines.adoc[Enabling AI pipelines].

* If you created your workbench before the pipeline server was available, you stopped and restarted the workbench.

.Procedure

. In the JupyterLab pipeline editor toolbar, click *Run Pipeline*.
+
image::pipelines/wb-pipeline-run-button.png[Pipeline Run Button, 300]

. Enter a name for your pipeline.
. Verify that the *Runtime Configuration:* is set to `Pipeline`.
. Click *OK*.
+
*NOTE:* If you see an error message stating that "no runtime configuration for AI Pipeline is defined", you might have created your workbench before the pipeline server was available. To address this error, you must verify that you configured the pipeline server and then restart the workbench.

. In the {productname-short} dashboard, open your project and expand the newly created pipeline.
+
image::pipelines/dsp-pipeline-complete.png[New pipeline expanded, 800]

. Click *View runs*.
+
image::pipelines/dsp-view-run.png[View runs for selected pipeline, 500]

. Click your run and then view the pipeline run in progress.
+
image::pipelines/pipeline-run-complete.png[Pipeline run progress, 800]

.Verification

* The `models/fraud/1/model.onnx` file is in your S3 bucket.


.Next step

* (Optional) xref:running-a-pipeline-generated-from-python-code.adoc[Running a pipeline generated from Python code]

* Serve the model, as described in xref:preparing-the-model-for-deployment.adoc[Preparing a model for deployment].
