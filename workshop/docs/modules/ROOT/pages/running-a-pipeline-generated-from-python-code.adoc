[id='running-a-pipeline-generated-from-python-code']
= Running a data science pipeline generated from Python code

In the previous section, you created a simple pipeline by using the GUI pipeline editor. It's often desirable to create pipelines by using code that can be version-controlled and shared with others. The https://github.com/kubeflow/kfp-tekton[kfp-tekton] SDK provides a Python API for creating pipelines. The SDK is available as a Python package that you can install by using the `pip install kfp-tekton~=1.5.9` command. With this package, you can use Python code to create a pipeline and then compile it to Tekton YAML. Then you can import the YAML code into {productname-short}.

This {deliverable} does not delve into the details of how to use the SDK. Instead, it provides the files for you to view and upload.

. Optionally, view the provided Python code in your Jupyter environment by navigating to the `fraud-detection-notebooks` project's `pipeline` directory. It contains the following files:
+
* `6_get_data_train_upload.py` is the main pipeline code.
* `get_data.py`, `train_model.py`, and `upload.py` are the three components of the pipeline.
* `build.sh` is a script that builds the pipeline and creates the YAML file. 
+
For your convenience, the output of the `build.sh` script is provided in the `5_get_data_train_upload.yaml` file. The `5_get_data_train_upload.yaml` output file is located in the top-level `fraud-detection` directory.

. Right-click the `5_get_data_train_upload.yaml` file and then click *Download*.

. Upload the `5_get_data_train_upload.yaml` file to {productname-short}.

.. In the {productname-short} dashboard, navigate to your data science project page and then click *Import pipeline*.
+
image::pipelines/dsp-pipeline-import.png[]

.. Enter values for *Pipeline name* and *Pipeline description*.

.. Click *Upload* and then select `5_get_data_train_upload.yaml` from your local files to upload the pipeline.
+
image::pipelines/dsp-pipline-import-upload.png[]

.. Click *Import pipeline* to import and save the pipeline.
+
The pipeline shows in the list of pipelines.

. Expand the pipeline item and then click *View runs*.
+
image::pipelines/dsp-pipline-view-runs.png[]

. Click *Create run*.

. On the *Create run* page, provide the following values:
.. For *Name*, type any name, for example `Run 1`.
.. For *Pipeline*, select the pipeline that you uploaded.
+
 You can leave the other fields with their default values.
+
image::pipelines/pipeline-create-run-form.png[Create Pipeline Run form]

. Click *Create* to create the run.
+
A new run starts immediately and opens the run details page.
+
image::pipelines/pipeline-run-in-progress.png[]

There you have it:  a pipeline created in Python that is running in {productname-short}.





